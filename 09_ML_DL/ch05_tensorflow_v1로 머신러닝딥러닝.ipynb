{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Tensorflow v2.x에서 v1버전 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tjoeun\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "#경고는 나오지만 그냥 실행합시다.\n",
    "#버전 2를 비활성화했으니 1로 사용 가능해졌다!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello,Tensorflow'\n",
      "Hello,Tensorflow\n"
     ]
    }
   ],
   "source": [
    "#tensor = data, 연산. 데이터는 상수일수도, 변수일수도 있다.\n",
    "# node1 상수 tensor 선언\n",
    "node1=tf.constant(\"Hello,Tensorflow\")\n",
    "#graph(computational graph를 생성)\n",
    "sess=tf.Session()\n",
    "#print(nodel)\n",
    "print(sess.run(node1)) # b가 의미하는 것은 byte literals\n",
    "# http://stackoverflow.com/questions/6269765\n",
    "print(sess.run(node1).decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.0, 20.0, 30.0]\n"
     ]
    }
   ],
   "source": [
    "# 간단한 수학 연산 수행(computational graph)\n",
    "node1 = tf.constant(10, dtype=tf.float32)\n",
    "node2 = tf.constant(20, dtype=tf.float32)\n",
    "# node3 = node1 + node2\n",
    "node3 = tf.add(node1, node2)\n",
    "# computational graph 실행\n",
    "sess = tf.Session()\n",
    "print(sess.run([node1, node2, node3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorflow\n",
    "- 그래프 정의\n",
    "- tf.Session()을 실행\n",
    "- sess.run()을 통해 값을 확인할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "[1. 2. 3.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "node1 = tf.constant(np.array([1,2,3]), dtype=tf.int16)\n",
    "node2 = tf.cast(node1, dtype=tf.float32)\n",
    "sess = tf.Session()\n",
    "print(sess.run(node1))\n",
    "print(sess.run(node2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5\n"
     ]
    }
   ],
   "source": [
    "data = [1.,2.,3.,4.]\n",
    "m = tf.reduce_mean(data) # reduce_mean 평균값 연산\n",
    "sess = tf.Session()\n",
    "print(sess.run(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  v1을 이용한 linear regression을 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 독립변수 x가 한개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200번째 cost:0.010188550688326359, W값:[0.8830482], b값:[0.265859]\n",
      "400번째 cost:0.0038904882967472076, W값:[0.9277309], b값:[0.16428469]\n",
      "600번째 cost:0.0014855748740956187, W값:[0.9553421], b값:[0.10151782]\n",
      "800번째 cost:0.0005672649131156504, W값:[0.9724042], b값:[0.06273179]\n",
      "1000번째 cost:0.00021660754282493144, W값:[0.98294747], b값:[0.03876433]\n",
      "1200번째 cost:8.271255501313135e-05, W값:[0.98946244], b값:[0.02395406]\n",
      "1400번째 cost:3.1582963856635615e-05, W값:[0.99348855], b값:[0.01480209]\n",
      "1600번째 cost:1.2060066183039453e-05, W값:[0.9959763], b값:[0.00914677]\n",
      "1800번째 cost:4.604971309163375e-06, W값:[0.9975136], b값:[0.00565213]\n",
      "2000번째 cost:1.7584810620974167e-06, W값:[0.9984635], b값:[0.00349271]\n",
      "2200번째 cost:6.716065854561748e-07, W값:[0.99905044], b값:[0.00215845]\n",
      "2400번째 cost:2.565503791629453e-07, W값:[0.9994131], b값:[0.0013341]\n",
      "2600번째 cost:9.8066465170632e-08, W값:[0.9996371], b값:[0.00082484]\n",
      "2800번째 cost:3.752963095848827e-08, W값:[0.9997754], b값:[0.00051015]\n",
      "3000번째 cost:1.4369356371446429e-08, W값:[0.9998611], b값:[0.0003158]\n",
      "3200번째 cost:5.5110778163225405e-09, W값:[0.99991393], b값:[0.00019557]\n",
      "3400번째 cost:2.1225585733475327e-09, W값:[0.9999465], b값:[0.00012129]\n",
      "3600번째 cost:8.142713170400384e-10, W값:[0.9999669], b값:[7.5082e-05]\n",
      "3800번째 cost:3.192312247879414e-10, W값:[0.9999795], b값:[4.706821e-05]\n",
      "4000번째 cost:1.1734023475096222e-10, W값:[0.9999874], b값:[2.8583154e-05]\n",
      "4200번째 cost:4.6769383504896567e-11, W값:[0.99999195], b값:[1.8014396e-05]\n",
      "4400번째 cost:2.079068341098722e-11, W값:[0.9999946], b값:[1.19844435e-05]\n",
      "4600번째 cost:1.0831627261786991e-11, W값:[0.999996], b값:[8.553058e-06]\n",
      "4800번째 cost:6.576293763022045e-12, W값:[0.9999969], b값:[6.6052403e-06]\n",
      "5000번째 cost:4.6588206382980335e-12, W값:[0.9999974], b값:[5.510808e-06]\n",
      "5200번째 cost:3.800521095748133e-12, W값:[0.9999976], b값:[4.8709685e-06]\n",
      "5400번째 cost:3.2466893756799564e-12, W값:[0.99999774], b값:[4.5478346e-06]\n",
      "5600번째 cost:3.243234023356245e-12, W값:[0.99999774], b값:[4.4912313e-06]\n",
      "5800번째 cost:3.243232722313638e-12, W값:[0.99999774], b값:[4.4902354e-06]\n",
      "6000번째 cost:3.243232722313638e-12, W값:[0.99999774], b값:[4.4902276e-06]\n"
     ]
    }
   ],
   "source": [
    "# tensor graph 정의\n",
    "\n",
    "# train data set\n",
    "# x = np.array([1,2,3])\n",
    "# y = np.array([1,2,3])\n",
    "x = [1,2,3]\n",
    "y = [1,2,3]\n",
    "\n",
    "#Weight & Bias (처음에는 랜덤값을 셋팅했다가 학습과정에서 변경)\n",
    "W = tf.Variable(tf.random.normal([1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random.normal([1]), name=\"bias\")\n",
    "\n",
    "# Hypothesis\n",
    "H = W*x + b\n",
    "\n",
    "# cost function(최소제곱법)\n",
    "cost = tf.reduce_mean(tf.square(H - y))\n",
    "\n",
    "# 우리의 목적은 cost함수가 최소가 되는 W와 b를 찾는 것\n",
    "'''\n",
    "cost함수는 제곱의 평균인 2차 함수이므로 곡선. 곡선위 미분값이 줄어드는 방향으로 학습\n",
    "'''\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Session \n",
    "sess = tf.Session()\n",
    "\n",
    "# Variable 노드 초기화\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 6000번 학습 (tensorflow v2. fit()함수)\n",
    "'''\n",
    "for step in range(1, 6001):\n",
    "    sess.run(train)\n",
    "    if step%300 == 0:\n",
    "        print(\"{}번째 cost:{}, W값:{}, b값:{}\".format(step, \n",
    "                        sess.run(cost), sess.run(W), sess.run(b)))\n",
    "'''\n",
    "for step in range(1, 6001):\n",
    "    _, cost_val, W_val, b_val = sess.run([train, cost, W, b])\n",
    "    if step%200 == 0:\n",
    "        print(\"{}번째 cost:{}, W값:{}, b값:{}\".format(step,\n",
    "                        cost_val, W_val, b_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.99999774], dtype=float32), array([4.4902276e-06], dtype=float32)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run([W,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_, b_ = sess.run([W,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종적으로 나온 회귀식 : H=0.9999977350234985*x + 4.490227638598299e-06\n"
     ]
    }
   ],
   "source": [
    "print(\"최종적으로 나온 회귀식 : H={}*x + {}\".format(w_[0], b_[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번째 cost:3.243232722313638e-12, W값:100.0, b값:0.9731490612030029\n",
      "201번째 cost:3.243232722313638e-12, W값:10.697290420532227, b값:-22.044218063354492\n",
      "401번째 cost:3.243232722313638e-12, W값:6.992336273193359, b값:-13.621989250183105\n",
      "601번째 cost:3.243232722313638e-12, W값:4.702901840209961, b값:-8.417566299438477\n",
      "801번째 cost:3.243232722313638e-12, W값:3.2881667613983154, b값:-5.201540470123291\n",
      "1001번째 cost:3.243232722313638e-12, W값:2.4139480590820312, b값:-3.2142364978790283\n",
      "1201번째 cost:3.243232722313638e-12, W값:1.8737339973449707, b값:-1.9862028360366821\n",
      "1401번째 cost:3.243232722313638e-12, W값:1.5399144887924194, b값:-1.2273527383804321\n",
      "1601번째 cost:3.243232722313638e-12, W값:1.3336344957351685, b값:-0.7584295272827148\n",
      "1801번째 cost:3.243232722313638e-12, W값:1.2061657905578613, b값:-0.46866321563720703\n",
      "2001번째 cost:3.243232722313638e-12, W값:1.127397894859314, b값:-0.28960514068603516\n",
      "2201번째 cost:3.243232722313638e-12, W값:1.0787240266799927, b값:-0.17895829677581787\n",
      "2401번째 cost:3.243232722313638e-12, W값:1.0486469268798828, b값:-0.11058565229177475\n",
      "2601번째 cost:3.243232722313638e-12, W값:1.0300607681274414, b값:-0.0683353915810585\n",
      "2801번째 cost:3.243232722313638e-12, W값:1.0185757875442505, b값:-0.04222707450389862\n",
      "3001번째 cost:3.243232722313638e-12, W값:1.0114786624908447, b값:-0.026093697175383568\n",
      "3201번째 cost:3.243232722313638e-12, W값:1.0070931911468506, b값:-0.01612435095012188\n",
      "3401번째 cost:3.243232722313638e-12, W값:1.0043830871582031, b값:-0.00996391475200653\n",
      "3601번째 cost:3.243232722313638e-12, W값:1.0027086734771729, b값:-0.006157306954264641\n",
      "3801번째 cost:3.243232722313638e-12, W값:1.0016740560531616, b값:-0.0038052403833717108\n"
     ]
    }
   ],
   "source": [
    "# tensor graph 정의\n",
    "\n",
    "# train data set\n",
    "# x = np.array([1,2,3])\n",
    "# y = np.array([1,2,3])\n",
    "x = [1,2,3]\n",
    "y = [1,2,3]\n",
    "\n",
    "#Weight & Bias (처음에는 랜덤값을 셋팅했다가 학습과정에서 변경)\n",
    "W = tf.Variable(100.0, name=\"weight\")\n",
    "b = tf.Variable(tf.random.normal([1]), name=\"bias\")\n",
    "\n",
    "# Hypothesis\n",
    "H = W*x + b\n",
    "\n",
    "# cost function(최소제곱법)\n",
    "cost = tf.reduce_mean(tf.square(H - y))\n",
    "\n",
    "# 우리의 목적은 cost함수가 최소가 되는 W와 b를 찾는 것\n",
    "'''\n",
    "cost함수는 제곱의 평균인 2차 함수이므로 곡선. 곡선위 미분값이 줄어드는 방향으로 학습\n",
    "'''\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Session \n",
    "sess = tf.Session()\n",
    "\n",
    "# Variable 노드 초기화\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 4000번 학습 (tensorflow v2. fit()함수)\n",
    "for step in range(1, 4001):\n",
    "    W_val, b_val = sess.run([W, b])\n",
    "    if step%200 == 1:\n",
    "        print(\"{}번째 cost:{}, W값:{}, b값:{}\".format(step,\n",
    "                        cost_val, W_val, b_val[0]))\n",
    "    sess.run(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 predict를 하기 위한 placeholder 노드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# placeholder 이용\n",
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "#ab = tf.add(a+b)\n",
    "ab = a + b\n",
    "sess = tf.Session()\n",
    "sess.run(ab, feed_dict={a:10, b:20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11., 12., 13.], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(ab, feed_dict={a : [1,2,3],\n",
    "                        b : [10,10,10]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11., 12., 13.], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(ab, feed_dict={a : np.array([1,2,3]),\n",
    "                        b : np.array([10,10,10])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200번째:cost-0.36940088868141174, W-[2.704206], b-[1.3991745]\n",
      "400번째:cost-0.14105521142482758, W-[2.4351566], b-[2.010787]\n",
      "600번째:cost-0.053862065076828, W-[2.2689006], b-[2.3887255]\n",
      "800번째:cost-0.020567193627357483, W-[2.1661646], b-[2.622269]\n",
      "1000번째:cost-0.007853571325540543, W-[2.1026797], b-[2.766585]\n",
      "1200번째:cost-0.002998870564624667, W-[2.0634496], b-[2.8557642]\n",
      "1400번째:cost-0.0011451252503320575, W-[2.0392082], b-[2.9108706]\n",
      "1600번째:cost-0.0004372670082375407, W-[2.0242286], b-[2.944923]\n",
      "1800번째:cost-0.00016697606770321727, W-[2.014972], b-[2.9659653]\n",
      "2000번째:cost-6.376473174896091e-05, W-[2.0092518], b-[2.9789684]\n",
      "2200번째:cost-2.434770249237772e-05, W-[2.005717], b-[2.987004]\n",
      "2400번째:cost-9.298728400608525e-06, W-[2.0035334], b-[2.9919684]\n",
      "2600번째:cost-3.5519244647730375e-06, W-[2.0021842], b-[2.9950356]\n",
      "2800번째:cost-1.358426402475743e-06, W-[2.0013504], b-[2.9969301]\n",
      "3000번째:cost-5.19796856224275e-07, W-[2.0008357], b-[2.9981005]\n",
      "3200번째:cost-1.9955200514232274e-07, W-[2.0005183], b-[2.9988232]\n",
      "3400번째:cost-7.652162281601704e-08, W-[2.0003211], b-[2.9992712]\n",
      "3600번째:cost-2.9765715225948952e-08, W-[2.0002005], b-[2.9995458]\n",
      "3800번째:cost-1.1620310935711586e-08, W-[2.0001254], b-[2.999716]\n",
      "4000번째:cost-4.665404507164794e-09, W-[2.0000784], b-[2.99982]\n",
      "4200번째:cost-1.8624177755555138e-09, W-[2.00005], b-[2.9998863]\n",
      "4400번째:cost-6.410421637959018e-10, W-[2.0000296], b-[2.999934]\n",
      "4600번째:cost-4.848364487664014e-10, W-[2.000026], b-[2.999942]\n",
      "4800번째:cost-4.848364487664014e-10, W-[2.000026], b-[2.999942]\n",
      "5000번째:cost-4.848364487664014e-10, W-[2.000026], b-[2.999942]\n",
      "5200번째:cost-4.848364487664014e-10, W-[2.000026], b-[2.999942]\n",
      "5400번째:cost-4.848364487664014e-10, W-[2.000026], b-[2.999942]\n",
      "5600번째:cost-4.848364487664014e-10, W-[2.000026], b-[2.999942]\n",
      "5800번째:cost-4.848364487664014e-10, W-[2.000026], b-[2.999942]\n",
      "6000번째:cost-4.848364487664014e-10, W-[2.000026], b-[2.999942]\n"
     ]
    }
   ],
   "source": [
    "# training data set (H = 2x + 3)\n",
    "x_data = [1, 2, 3]\n",
    "y_data = [5, 7, 9]\n",
    "\n",
    "# placeholder 설정\n",
    "x = tf.placeholder(dtype=tf.float32)\n",
    "y = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random_normal([1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "# Hypothesis\n",
    "H = W*x + b\n",
    "\n",
    "# cost function\n",
    "cost = tf.reduce_mean(tf.square(H - y))\n",
    "\n",
    "# 경사하강법\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Session & Variable 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# 학습\n",
    "for step in range(1, 6001):\n",
    "    _, cost_val, W_val, b_val = sess.run([train, cost, W, b], \n",
    "                                feed_dict={x:x_data, y:y_data})\n",
    "    if step%200==0:\n",
    "        print(\"{}번째:cost-{}, W-{}, b-{}\".format(step, \n",
    "                                                cost_val, W_val, b_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([2.000026], dtype=float32), array([2.999942], dtype=float32)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run([W, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.000072], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측해보기(predict)\n",
    "sess.run(H, feed_dict={x:5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.999968, 23.000202, 43.00046 ], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(H, feed_dict={x: np.array([1,10,20])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 scale이 다른 데이터들의 linear regression을 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200번째 cost-79.26947784423828, W-[10.071943]\n",
      "400번째 cost-79.15138244628906, W-[10.133233]\n",
      "600번째 cost-79.14055633544922, W-[10.151798]\n",
      "800번째 cost-79.13954162597656, W-[10.157421]\n",
      "1000번째 cost-79.13948059082031, W-[10.159123]\n",
      "1200번째 cost-79.13945007324219, W-[10.159639]\n",
      "1400번째 cost-79.13944244384766, W-[10.159796]\n",
      "1600번째 cost-79.13946533203125, W-[10.159843]\n",
      "1800번째 cost-79.13946533203125, W-[10.159858]\n",
      "2000번째 cost-79.13945007324219, W-[10.159862]\n",
      "2200번째 cost-79.13944244384766, W-[10.1598625]\n",
      "2400번째 cost-79.13945770263672, W-[10.1598625]\n",
      "2600번째 cost-79.13945770263672, W-[10.1598625]\n",
      "2800번째 cost-79.13945770263672, W-[10.1598625]\n",
      "3000번째 cost-79.13945770263672, W-[10.1598625]\n",
      "3200번째 cost-79.13945770263672, W-[10.1598625]\n",
      "3400번째 cost-79.13945770263672, W-[10.1598625]\n",
      "3600번째 cost-79.13945770263672, W-[10.1598625]\n",
      "3800번째 cost-79.13945770263672, W-[10.1598625]\n",
      "4000번째 cost-79.13945770263672, W-[10.1598625]\n",
      "4200번째 cost-79.13945770263672, W-[10.1598625]\n",
      "4400번째 cost-79.13945770263672, W-[10.1598625]\n",
      "4600번째 cost-79.13945770263672, W-[10.1598625]\n",
      "4800번째 cost-79.13945770263672, W-[10.1598625]\n",
      "5000번째 cost-79.13945770263672, W-[10.1598625]\n",
      "5200번째 cost-79.13945770263672, W-[10.1598625]\n",
      "5400번째 cost-79.13945770263672, W-[10.1598625]\n",
      "5600번째 cost-79.13945770263672, W-[10.1598625]\n",
      "5800번째 cost-79.13945770263672, W-[10.1598625]\n",
      "6000번째 cost-79.13945770263672, W-[10.1598625]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# training data set (datadml scale이 다르면 학습 결과가 ?)\n",
    "x_data = [1, 2, 5, 8,10]\n",
    "y_data = [5,15,68,80,95]\n",
    "\n",
    "# placeholder를 설정\n",
    "x = tf.placeholder(dtype=tf.float32, shape=None)\n",
    "y = tf.placeholder(dtype=tf.float32, shape=None)\n",
    "#shape:어떤게 들어올지 지정. none면 아무거나 들어올 것. \n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random_normal([1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "# Hypothesis\n",
    "H = W * x + b\n",
    "\n",
    "# cost function\n",
    "cost = tf.reduce_mean(tf.square(H - y))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "# train     = optimizer.minimize(cost)\n",
    "\n",
    "# session & Variable 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(1, 6001):\n",
    "    _, cost_val, W_val = sess.run([train, cost, W], feed_dict={x:x_data,\n",
    "                                                              y:y_data})\n",
    "    if step%200 == 0 :\n",
    "        print(\"{}번째 cost-{}, W-{}\".format(step, cost_val, W_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([10.1598625], dtype=float32), array([-0.23128414], dtype=float32)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run([W,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([101.36734], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#예측은 할 수 있지만 cost가 너무 커서 믿을수없어.\n",
    "sess.run(H, feed_dict={x:10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#예측잘안되는 이유: local min에서 멈춰서.\n",
    "#global min을 구하려면? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 독립변수 x가 여러개인 linear regression\n",
    "- scale이 다른 x,y값(교안 pt 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000번째 cost:3.106980323791504\n",
      "6000번째 cost:2.192689895629883\n",
      "9000번째 cost:1.814903974533081\n",
      "12000번째 cost:1.5694506168365479\n",
      "15000번째 cost:1.373277187347412\n",
      "18000번째 cost:1.2067763805389404\n",
      "21000번째 cost:1.0634634494781494\n",
      "24000번째 cost:0.9396953582763672\n",
      "27000번째 cost:0.8326910734176636\n",
      "30000번째 cost:0.7401959896087646\n",
      "33000번째 cost:0.6602194905281067\n",
      "36000번째 cost:0.5911039113998413\n",
      "39000번째 cost:0.5313214659690857\n",
      "42000번째 cost:0.47965317964553833\n",
      "45000번째 cost:0.4349750876426697\n",
      "48000번째 cost:0.3963364064693451\n",
      "51000번째 cost:0.3629487156867981\n",
      "54000번째 cost:0.33406469225883484\n",
      "57000번째 cost:0.309099406003952\n",
      "60000번째 cost:0.28751641511917114\n"
     ]
    }
   ],
   "source": [
    "# training data set\n",
    "# x_data = [[73,80,75],\n",
    "#           [93,88,93],\n",
    "#           [89,91,90],\n",
    "#           [96,98,100],\n",
    "#           [73,66,70]]\n",
    "# y_data = [[152],[185],[180],[196],[142]]\n",
    "x_data = np.array([[73,80,75],\n",
    "                   [93,88,93],\n",
    "                   [89,91,90],\n",
    "                   [96,98,100],\n",
    "                   [73,66,70]])\n",
    "y_data = np.array([[152],\n",
    "                   [185],\n",
    "                   [180],\n",
    "                   [196],\n",
    "                   [142]])\n",
    "\n",
    "# placeholder \n",
    "X = tf.placeholder(shape=[None, 3], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random_normal([3,1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "# Hypothesis\n",
    "# H = X @ W + b\n",
    "H = tf.matmul(X, W) + b\n",
    "\n",
    "# cost function\n",
    "cost = tf.reduce_mean(tf.square(H - Y))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-5).minimize(cost)\n",
    "\n",
    "# session & Variable 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(1, 60001):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict={X:x_data, \n",
    "                                                    Y : y_data})\n",
    "    if step%3000 == 0 :\n",
    "        print(\"{}번째 cost:{}\".format(step, cost_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 오존량 예측 예제\n",
    "- 독립변수 x가 3 => Multi-variable Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000번째 cost 529.0515747070312\n",
      "6000번째 cost 471.0494079589844\n",
      "9000번째 cost 464.23199462890625\n",
      "12000번째 cost 463.4087829589844\n",
      "15000번째 cost 463.2874755859375\n",
      "18000번째 cost 463.2484436035156\n",
      "21000번째 cost 463.21917724609375\n",
      "24000번째 cost 463.1909484863281\n",
      "27000번째 cost 463.1629638671875\n",
      "30000번째 cost 463.1350402832031\n",
      "33000번째 cost 463.1070556640625\n",
      "36000번째 cost 463.07904052734375\n",
      "39000번째 cost 463.05108642578125\n",
      "42000번째 cost 463.023193359375\n",
      "45000번째 cost 462.9952392578125\n",
      "48000번째 cost 462.96734619140625\n",
      "51000번째 cost 462.93939208984375\n",
      "54000번째 cost 462.9115295410156\n",
      "57000번째 cost 462.8836975097656\n",
      "60000번째 cost 462.8558654785156\n"
     ]
    }
   ],
   "source": [
    "# training data set 생성\n",
    "# data load -> 결측치 처리 -> 독립변수, 종속변수 분리\n",
    "data = pd.read_csv('./data/ozone.csv', sep=\",\")\n",
    "\n",
    "# data를 바로 학습할 수 없음. 데이터 정제 작업 필요.\n",
    "data = data.dropna(how='any') # 결측치가 한열이라도 있는 행 모두 제거\n",
    "\n",
    "# 필요한 columns만 추출\n",
    "data = data[['Ozone','Solar.R','Wind','Temp']]\n",
    "\n",
    "# training data set\n",
    "x_data = data[['Solar.R','Wind','Temp']].values # DataFrame을 numpy 배열로\n",
    "y_data = data[['Ozone']].values.reshape(-1, 1)\n",
    "x_data.shape, y_data.shape\n",
    "\n",
    "# tensorflow 구현\n",
    "# 1.placeholder\n",
    "X = tf.placeholder(shape=[None,3], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "\n",
    "# 2. Weight & bias 설정\n",
    "W = tf.Variable(tf.random_normal([3,1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "# 3. Hypothesis\n",
    "# H = X @ W + b\n",
    "H = tf.matmul(X, W) + b\n",
    "\n",
    "# 4. cost 함수\n",
    "cost = tf.reduce_mean(tf.square(H - Y))\n",
    "\n",
    "# 5. train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-5).minimize(cost)\n",
    "\n",
    "# 6. session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 7. 학습\n",
    "for step in range(1, 60001):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict={X:x_data,\n",
    "                                                    Y:y_data})\n",
    "    if step%3000 == 0:\n",
    "        print(\"{}번째 cost {}\".format(step, cost_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ozone</th>\n",
       "      <th>Solar.R</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ozone  Solar.R  Wind  Temp\n",
       "1   36.0    118.0   8.0    72"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[41.47469]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(H, feed_dict={X:np.array([[118,8,72]])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# scale 맞추는 방법 : normalization(많이 씀), standardization(표준화)\n",
    "#                   X - Xmin\n",
    "# normalization = ──────────────\n",
    "#                  Xmax - Xmin\n",
    "# 위의 식을 써도 되지만 라이브러리를 씀(sklearn.preprocessing.MinMaxScaler 이용)\n",
    "#                    x - Xmean(평균)\n",
    "# standardization = ────────────────\n",
    "#                     Xstd(표준편차)\n",
    "# 의 식을 써도 되지만 라이브러리 씀(sklearn.preprocessing.StandardScaler 이용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3000번째 cost 3.665651321411133\n",
      " 6000번째 cost 3.2864339351654053\n",
      " 9000번째 cost 2.9518892765045166\n",
      "12000번째 cost 2.656644582748413\n",
      "15000번째 cost 2.3959689140319824\n",
      "18000번째 cost 2.1657209396362305\n",
      "21000번째 cost 1.9622740745544434\n",
      "24000번째 cost 1.7824524641036987\n",
      "27000번째 cost 1.6234549283981323\n",
      "30000번째 cost 1.48283851146698\n",
      "33000번째 cost 1.3584333658218384\n",
      "36000번째 cost 1.2483429908752441\n",
      "39000번째 cost 1.1508973836898804\n",
      "42000번째 cost 1.0646220445632935\n",
      "45000번째 cost 0.9882211685180664\n",
      "48000번째 cost 0.9205489754676819\n",
      "51000번째 cost 0.8606023192405701\n",
      "54000번째 cost 0.8074817657470703\n",
      "57000번째 cost 0.7604063153266907\n",
      "60000번째 cost 0.7186822891235352\n"
     ]
    }
   ],
   "source": [
    "# training data set 생성\n",
    "# data load -> 결측치 처리 -> 독립변수, 종속변수 분리\n",
    "data = pd.read_csv('./data/ozone.csv', sep=\",\")\n",
    "\n",
    "# data를 바로 학습할 수 없음. 데이터 정제 작업 필요.\n",
    "data = data.dropna(how='any') # 결측치가 한열이라도 있는 행 모두 제거\n",
    "\n",
    "# 필요한 columns만 추출\n",
    "data = data[['Ozone','Solar.R','Wind','Temp']]\n",
    "\n",
    "# scale 조정(standardization)\n",
    "#                    x - Xmean(평균)\n",
    "# standardization = ────────────────\n",
    "#                     Xstd(표준편차)\n",
    "data['Ozone'] = (data['Ozone']- data['Ozone'].mean())/data['Ozone'].std()\n",
    "data['Solar.R'] = (data['Solar.R']- data['Solar.R'].mean()) / data['Solar.R'].std()\n",
    "data['Wind'] = (data['Wind']- data['Wind'].mean())/data['Wind'].std()\n",
    "data['Temp'] = (data['Temp']- data['Temp'].mean())/data['Temp'].std()\n",
    "\n",
    "# training data set\n",
    "x_data = data[['Solar.R','Wind','Temp']].values # DataFrame을 numpy 배열로\n",
    "y_data = data[['Ozone']].values.reshape(-1, 1)\n",
    "x_data.shape, y_data.shape\n",
    "\n",
    "# tensorflow 구현\n",
    "# 1.placeholder\n",
    "X = tf.placeholder(shape=[None,3], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "\n",
    "# 2. Weight & bias 설정\n",
    "W = tf.Variable(tf.random_normal([3,1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "# 3. Hypothesis\n",
    "# H = X @ W + b\n",
    "H = tf.matmul(X, W) + b\n",
    "\n",
    "# 4. cost 함수\n",
    "cost = tf.reduce_mean(tf.square(H - Y))\n",
    "\n",
    "# 5. train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-5).minimize(cost)\n",
    "\n",
    "# 6. session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 7. 학습\n",
    "for step in range(1, 60001):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict={X:x_data,\n",
    "                                                    Y:y_data})\n",
    "    if step%3000 == 0:\n",
    "        print(\"{:5d}번째 cost {}\".format(step, cost_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict 하려면 scale이 맞춰진 데이터로 predict를 하고 결과를 다시 scale조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale 조정 전 데이터 : \n",
      " [[190.    7.4  67.   41. ]\n",
      " [118.    8.   72.   36. ]\n",
      " [149.   12.6  74.   12. ]]\n",
      "scale 조정된 데이터 :\n",
      " [[0.55963303 0.27717391 0.25       0.23952096]\n",
      " [0.33944954 0.30978261 0.375      0.20958084]\n",
      " [0.43425076 0.55978261 0.425      0.06586826]]\n",
      " 3000번째 cost 0.7461623549461365\n",
      " 6000번째 cost 0.618114173412323\n",
      " 9000번째 cost 0.5143833756446838\n",
      "12000번째 cost 0.4303322732448578\n",
      "15000번째 cost 0.36220911145210266\n",
      "18000번째 cost 0.3069766163825989\n",
      "21000번째 cost 0.26217710971832275\n",
      "24000번째 cost 0.2258211225271225\n",
      "27000번째 cost 0.19630081951618195\n",
      "30000번째 cost 0.17231197655200958\n",
      "33000번째 cost 0.15280240774154663\n",
      "36000번째 cost 0.13691529631614685\n",
      "39000번째 cost 0.12396369129419327\n",
      "42000번째 cost 0.11338749527931213\n",
      "45000번째 cost 0.10473453253507614\n",
      "48000번째 cost 0.09763950854539871\n",
      "51000번째 cost 0.09180513024330139\n",
      "54000번째 cost 0.08699236810207367\n",
      "57000번째 cost 0.08300714194774628\n",
      "60000번째 cost 0.07969272881746292\n"
     ]
    }
   ],
   "source": [
    "# training data set 생성\n",
    "# data load -> 결측치 처리 -> 독립변수, 종속변수 분리\n",
    "data = pd.read_csv('./data/ozone.csv', sep=\",\")\n",
    "\n",
    "# data를 바로 학습할 수 없음. 데이터 정제 작업 필요.\n",
    "data = data.dropna(how='any') # 결측치가 한열이라도 있는 행 모두 제거\n",
    "\n",
    "# 필요한 columns만 추출\n",
    "data = data[['Ozone','Solar.R','Wind','Temp']]\n",
    "\n",
    "# training data set\n",
    "x_data = data[['Solar.R','Wind','Temp']].values # DataFrame을 numpy 배열로\n",
    "y_data = data[['Ozone']].values.reshape(-1, 1)\n",
    "\n",
    "print('scale 조정 전 데이터 : \\n', np.c_[x_data[:3], y_data[:3]])\n",
    "# scale 조정(1) sklearn.preprocessing.MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scale_x = MinMaxScaler() # scale_x : x_data를 scale조정할 객체\n",
    "# x_data에 대한 설정을 잡는 부분 ; x_data 3개 컬럼에 대한 max, min 설정\n",
    "scale_x.fit(x_data) \n",
    "x_data = scale_x.transform(x_data) # scale 조정된 x_data\n",
    "\n",
    "scale_y = MinMaxScaler()\n",
    "scale_y.fit(y_data)\n",
    "y_data = scale_y.transform(y_data) # scale 조정된 y_data\n",
    "print('scale 조정된 데이터 :\\n', np.c_[x_data[:3], y_data[:3]])\n",
    "\n",
    "# tensorflow 구현\n",
    "# 1.placeholder\n",
    "X = tf.placeholder(shape=[None,3], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "\n",
    "# 2. Weight & bias 설정\n",
    "W = tf.Variable(tf.random_normal([3,1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "# 3. Hypothesis\n",
    "# H = X @ W + b\n",
    "H = tf.matmul(X, W) + b\n",
    "\n",
    "# 4. cost 함수\n",
    "cost = tf.reduce_mean(tf.square(H - Y))\n",
    "\n",
    "# 5. train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-5).minimize(cost)\n",
    "\n",
    "# 6. session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 7. 학습\n",
    "for step in range(1, 60001):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict={X:x_data,\n",
    "                                                    Y:y_data})\n",
    "    if step%3000 == 0:\n",
    "        print(\"{:5d}번째 cost {}\".format(step, cost_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. prediction\n",
    "input_data = np.array([[118., 8.,72.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원 데이터 :  [[118.   8.  72.]]\n",
      "scale 조정된 데이터 : [[0.33944954 0.30978261 0.375     ]]\n"
     ]
    }
   ],
   "source": [
    "scale_input_data = scale_x.transform(input_data)\n",
    "print('원 데이터 : ', input_data)\n",
    "print('scale 조정된 데이터 :', scale_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[67.23968]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_value = sess.run(H, feed_dict={X:scale_input_data})\n",
    "scale_y.inverse_transform(predict_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "조정전\n",
      " [[190.    7.4  67.   41. ]\n",
      " [118.    8.   72.   36. ]]\n",
      "조정후\n",
      " [[ 0.05728624 -0.71707784 -1.13764691 -0.03317961]\n",
      " [-0.73618283 -0.54766534 -0.61060682 -0.18411965]]\n",
      " 3000번째 cost 2.9512012004852295\n",
      " 6000번째 cost 2.6608684062957764\n",
      " 9000번째 cost 2.4042627811431885\n",
      "12000번째 cost 2.1773722171783447\n",
      "15000번째 cost 1.9766675233840942\n",
      "18000번째 cost 1.799068570137024\n",
      "21000번째 cost 1.6418483257293701\n",
      "24000번째 cost 1.5026202201843262\n",
      "27000번째 cost 1.3792812824249268\n",
      "30000번째 cost 1.2699828147888184\n",
      "33000번째 cost 1.1730953454971313\n",
      "36000번째 cost 1.0871796607971191\n",
      "39000번째 cost 1.010970950126648\n",
      "42000번째 cost 0.9433571100234985\n",
      "45000번째 cost 0.8833332657814026\n",
      "48000번째 cost 0.8300508260726929\n",
      "51000번째 cost 0.7827309966087341\n",
      "54000번째 cost 0.7406808137893677\n",
      "57000번째 cost 0.7033111453056335\n",
      "60000번째 cost 0.6700924038887024\n"
     ]
    }
   ],
   "source": [
    "# training data set 생성\n",
    "# data load -> 결측치 처리 -> 독립변수, 종속변수 분리\n",
    "data = pd.read_csv('./data/ozone.csv', sep=\",\")\n",
    "\n",
    "# data를 바로 학습할 수 없음. 데이터 정제 작업 필요.\n",
    "data = data.dropna(how='any') # 결측치가 한열이라도 있는 행 모두 제거\n",
    "\n",
    "# 필요한 columns만 추출\n",
    "data = data[['Ozone','Solar.R','Wind','Temp']]\n",
    "\n",
    "# scale 조정 : data를 한꺼번에 scale 조정 시 prediction 힘듦\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(data)\n",
    "# data = pd.DataFrame(scaler.transform(data),\n",
    "#                     columns=['Ozone','Solar.R','Wind','Temp'])\n",
    "\n",
    "# training data set\n",
    "x_data = data[['Solar.R','Wind','Temp']].values # DataFrame을 numpy 배열로\n",
    "y_data = data[['Ozone']].values.reshape(-1, 1)\n",
    "\n",
    "print('조정전\\n', np.c_[x_data[:2], y_data[:2]])\n",
    "# scale 조정 : x_data, y_data scale을 따로 따로 - prediction 가능\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_x = StandardScaler()\n",
    "scaler_x.fit(x_data)\n",
    "x_data = scaler_x.transform(x_data)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "scaler_y.fit(y_data)\n",
    "y_data = scaler_y.transform(y_data)\n",
    "print('조정후\\n', np.c_[x_data[:2], y_data[:2]])\n",
    "\n",
    "# tensorflow 구현\n",
    "# 1.placeholder\n",
    "X = tf.placeholder(shape=[None,3], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "\n",
    "# 2. Weight & bias 설정\n",
    "W = tf.Variable(tf.random_normal([3,1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "# 3. Hypothesis\n",
    "# H = X @ W + b\n",
    "H = tf.matmul(X, W) + b\n",
    "\n",
    "# 4. cost 함수\n",
    "cost = tf.reduce_mean(tf.square(H - Y))\n",
    "\n",
    "# 5. train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-5).minimize(cost)\n",
    "\n",
    "# 6. session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 7. 학습\n",
    "for step in range(1, 60001):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict={X:x_data,\n",
    "                                                    Y:y_data})\n",
    "    if step%3000 == 0:\n",
    "        print(\"{:5d}번째 cost {}\".format(step, cost_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25.418083]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = np.array([[118.,8.,72.]])\n",
    "scaled_input_data = scale_x.transform(input_data)\n",
    "scaler_y.inverse_transform(sess.run(H, feed_dict={X:scaled_input_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.13812561],\n",
       "        [-0.5339741 ],\n",
       "        [ 0.2699776 ]], dtype=float32),\n",
       " array([-0.48627904], dtype=float32)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sess.run([W, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 logistic Regression= Binary classification(P/F) 로지스틱 회귀분석. 2개 그룹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w값은  0.12925170068027214 ,b값은  -0.27210884353741516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d23a159df0>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# logistic Regression이 필요한 이유( 기존의 linear regression으로는 안되는 이유)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats #회귀식 도출가능\n",
    "\n",
    "x=np.array([1,2,5,8,10])\n",
    "y=np.array([0,0,0,1,1])\n",
    "lm=stats.linregress(x,y)\n",
    "print('w값은 ', lm[0],',b값은 ', lm[1])\n",
    "plt.scatter(x,y)\n",
    "plt.plot(x,x*lm[0]+lm[1],'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w값은  0.03500583430571762 ,b값은  0.1732788798133022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d23a2497f0>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=np.array([1,2,5,8,10,30])\n",
    "y=np.array([0,0,0,1,1,1])\n",
    "lm=stats.linregress(x,y)\n",
    "print('w값은 ', lm[0],',b값은 ', lm[1])\n",
    "plt.scatter(x,y)\n",
    "plt.plot(x,x*lm[0]+lm[1],'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 logistic RegressionRegression= multinomial classification(3개 이상 그룹으로 분류로 분류)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 교안 51p부터."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tjoeun\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300,0.3093104958534241\n",
      "600,0.23701895773410797\n",
      "900,0.2060544341802597\n",
      "1200,0.1863814741373062\n",
      "1500,0.17169418931007385\n",
      "1800,0.1598099172115326\n",
      "2100,0.1497507095336914\n",
      "2400,0.14100097119808197\n",
      "2700,0.13325510919094086\n",
      "3000,0.1263149082660675\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#training data set\n",
    "x_data = np.array([[10,0],\n",
    "                   [8,1],\n",
    "                   [3,3],\n",
    "                   [2,3],\n",
    "                   [5,1],\n",
    "                   [2,0],\n",
    "                   [1,0]])\n",
    "y_data = np.array([[1],\n",
    "                   [1],\n",
    "                   [1],\n",
    "                   [1],\n",
    "                   [0],\n",
    "                   [0],\n",
    "                   [0]])\n",
    "#placeholder\n",
    "X=tf.placeholder(shape=[None,2],dtype=tf.float32)\n",
    "Y=tf.placeholder(shape=[None,1],dtype=tf.float32)\n",
    "#7행 2열로 잡아버리면 predict도 반드시 7,2를 넣어야하니 None으로 한다.\n",
    "\n",
    "# Weight(2행 1열) & bias(1개)\n",
    "W=tf.Variable(tf.random_normal([2,1]),name=\"weight\")\n",
    "b=tf.Variable(tf.random_normal([1]),name='bias')\n",
    "\n",
    "# hypothesis\n",
    "# Logits=X@W+b 아래 식도 이것과 같다.\n",
    "logits=tf.matmul(X,W)+b\n",
    "H=tf.sigmoid(logits)\n",
    "\n",
    "# cast function\n",
    "cost=tf.reduce_mean(tf.square(H-Y))\n",
    "cost=tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,labels=Y))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# session & 초기화\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(1,3001):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict={X:x_data, Y:y_data})\n",
    "    if step%300==0:\n",
    "        print(\"{},{}\".format(step,cost_val))\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습이 잘 되었는지 확인\n",
    "# Accuracy\n",
    "predict = tf.cast(H>0.5,dtype=tf.float32)\n",
    "correct=tf.equal(predict,Y)\n",
    "accuracy=tf.reduce_mean(tf.cast(correct,dtype=tf.float32))\n",
    "sess.run(predict,feed_dict={X:x_data, Y:y_data})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(accuracy,feed_dict={X:x_data, Y:y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h결과:  [[0.96429783]]\n",
      "predict결과:  [[1.]]\n"
     ]
    }
   ],
   "source": [
    "# 예측\n",
    "print(\"h결과: \",sess.run(H,feed_dict={X:[[3,3]]}))\n",
    "print(\"predict결과: \",sess.run(predict,feed_dict={X:[[3,3]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. multinomial classification(3개이상 그룹)\n",
    "-퀴즈 1,2,3 성적과 출석에 따른 등급 붐류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300,1.171482801437378\n",
      "600,0.9479263424873352\n",
      "900,0.6730166077613831\n",
      "1200,0.5540671944618225\n",
      "1500,0.5014704465866089\n",
      "1800,0.44643259048461914\n",
      "2100,0.050498269498348236\n",
      "2400,0.045994509011507034\n",
      "2700,0.042675238102674484\n",
      "3000,0.0399901382625103\n",
      "3300,0.037721388041973114\n",
      "3600,0.03575257584452629\n",
      "3900,0.034012939780950546\n",
      "4200,0.032455869019031525\n",
      "4500,0.03104877471923828\n",
      "4800,0.029767658561468124\n",
      "5100,0.028594186529517174\n",
      "5400,0.02751391939818859\n",
      "5700,0.02651527337729931\n",
      "6000,0.02558857575058937\n"
     ]
    }
   ],
   "source": [
    "#training data set(rydks ㅔ 54)\n",
    "x_data=[[10,7,8,5],\n",
    "       [8,8,9,4],\n",
    "       [7,8,2,3],\n",
    "       [6,3,9,3],\n",
    "       [7,5,7,4],\n",
    "       [3,5,6,2],\n",
    "       [2,4,3,1]]\n",
    "#종속변수는 multinomial classfication에서는 원핫인코딩! \n",
    "y_data = [[1,0,0],\n",
    "         [1,0,0],\n",
    "         [0,1,0],\n",
    "         [0,1,0],\n",
    "         [0,1,0],\n",
    "         [0,0,1],\n",
    "         [0,0,1],]\n",
    "\n",
    "#placeholder\n",
    "X=tf.placeholder(shape=[None,4],dtype=tf.float32)\n",
    "Y=tf.placeholder(shape=[None,3],dtype=tf.float32)\n",
    "#7행 2열로 잡아버리면 predict도 반드시 7,2를 넣어야하니 None으로 한다.\n",
    "\n",
    "# Weight(4행 3열) & bias(3개)\n",
    "W=tf.Variable(tf.random_normal([4,3]),name=\"weight\")\n",
    "b=tf.Variable(tf.random_normal([3]),name='bias')\n",
    "\n",
    "# hypothesis\n",
    "# Logits=X@W+b \n",
    "logits=tf.matmul(X,W)+b\n",
    "#H=tf.nn.sigmoid(logits) 이렇게 했을때 깔끔하게 떨어지지 않는 것이 생겨서 softmax를 사용한다.\n",
    "#즉, 분류분석 최종단계에서 결과의 합이 1이 되도록 한다.\n",
    "H=tf.nn.softmax(logits) \n",
    "\n",
    "\n",
    "\n",
    "# cast function\n",
    "cost=tf.reduce_mean(tf.square(H-Y))\n",
    "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,labels=Y))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# session & 초기화\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(1,6001):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict={X:x_data, Y:y_data})\n",
    "    if step%300==0:\n",
    "        print(\"{},{}\".format(step,cost_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9777385  0.01957264 0.00268883]]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# 예측\n",
    "result=sess.run(H,feed_dict={X:[[8,8,9,4]]})\n",
    "print(result)\n",
    "print(result.argmax(axis=1)) #0번째 열만 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0 %\n"
     ]
    }
   ],
   "source": [
    "##accuracy 측정\n",
    "# H= 0.97 0.19 0.002 일 경우 H.argmax = 0\n",
    "# Y= 1   0    0     일 경우 Y.argmax=0\n",
    "predict = tf.argmax(H,axis=1) # 어떤 열의 값이 제일 큰지 index 반환\n",
    "correct = tf.equal(predict,tf.argmax(Y,1)) \n",
    "#print(sess.run(correct,feed_dict={X:x_data,Y:y_data}))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct,dtype=tf.float32))\n",
    "print(sess.run(accuracy,feed_dict={X:x_data,Y:y_data})*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR 교안 77\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300,0.693179726600647\n",
      "600,0.6931487917900085\n",
      "900,0.6931473016738892\n",
      "1200,0.6931472420692444\n",
      "1500,0.6931471824645996\n",
      "1800,0.6931472420692444\n",
      "2100,0.6931471824645996\n",
      "2400,0.6931471824645996\n",
      "2700,0.6931471824645996\n",
      "3000,0.6931471824645996\n",
      "정확도: 0.25\n"
     ]
    }
   ],
   "source": [
    "#training data set\n",
    "x_data=[[0,0],\n",
    "       [0,1],\n",
    "       [1,0],\n",
    "       [1,1]]\n",
    "y_data=[[0],[1],[1],[0]]\n",
    "#placeholder\n",
    "X=tf.placeholder(shape=[None,2],dtype=tf.float32)\n",
    "Y=tf.placeholder(shape=[None,1],dtype=tf.float32)\n",
    "# Weight & bias \n",
    "W=tf.Variable(tf.random_normal([2,1]),name=\"weight\")\n",
    "b=tf.Variable(tf.random_normal([1]),name='bias')\n",
    "\n",
    "# hypothesis\n",
    "# Logits=X@W+b \n",
    "logits=tf.matmul(X,W)+b\n",
    "#다중분류아니고 이중분류이므로 sigmoid\n",
    "H=tf.sigmoid(logits) \n",
    "\n",
    "# cast function\n",
    "cost=tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,labels=Y))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# session & 초기화\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(1,3001):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict={X:x_data, Y:y_data})\n",
    "    if step%300==0:\n",
    "        print(\"{},{}\".format(step,cost_val))\n",
    "\n",
    "# predict\n",
    "predict = tf.cast(H>0.5,dtype=tf.float32)\n",
    "correct=tf.equal(predict,Y) #F,T,F,T\n",
    "accuracy = tf.reduce_mean(tf.cast(correct,dtype=tf.float32))\n",
    "print('정확도:',sess.run(accuracy, feed_dict={X:x_data,Y:y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.50000215]]\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "predict = tf.cast(H>0.5,dtype=tf.float32)\n",
    "correct=tf.equal(predict,Y) #F,T,F,T\n",
    "accuracy = tf.reduce_mean(tf.cast(correct,dtype=tf.float32))\n",
    "print(sess.run(H,feed_dict={X:[[0,0]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning XOR 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇회째: 300, 코스트:0.0014476418728008866\n",
      "몇회째: 600, 코스트:0.0006298384978435934\n",
      "몇회째: 900, 코스트:0.0003887788625434041\n",
      "몇회째: 1200, 코스트:0.00027688179397955537\n",
      "몇회째: 1500, 코스트:0.000213260151213035\n",
      "몇회째: 1800, 코스트:0.0001729787909425795\n",
      "몇회째: 2100, 코스트:0.0001450979762012139\n",
      "몇회째: 2400, 코스트:0.00012458348646759987\n",
      "몇회째: 2700, 코스트:0.00010897005995502695\n",
      "몇회째: 3000, 코스트:9.653124288888648e-05\n",
      "정확도: 1.0\n"
     ]
    }
   ],
   "source": [
    "#training data set\n",
    "x_data=[[0,0],\n",
    "       [0,1],\n",
    "       [1,0],\n",
    "       [1,1]]\n",
    "y_data=[[0],[1],[1],[0]]\n",
    "#placeholder\n",
    "X=tf.placeholder(shape=[None,2],dtype=tf.float32)\n",
    "Y=tf.placeholder(shape=[None,1],dtype=tf.float32)\n",
    "\n",
    "# 레이어 추가\n",
    "\n",
    "\n",
    "# Weight & bias (layer1 = 입력 2개 출력 10개) #바이어스는 출력 수를 따름\n",
    "W1=tf.Variable(tf.random_normal([2,10]),name=\"weight1\")\n",
    "b1=tf.Variable(tf.random_normal([10]),name='bias1') \n",
    "layer1=tf.nn.relu(tf.matmul(X,W1)+b1)\n",
    "\n",
    "# Weight & bias (layer2 = 입력 10개 출력 20개) #바이어스는 출력 수를 따름\n",
    "W2=tf.Variable(tf.random_normal([10,20]),name=\"weight2\")\n",
    "b2=tf.Variable(tf.random_normal([20]),name='bias2') \n",
    "layer2=tf.nn.relu(tf.matmul(layer1,W2)+b2)\n",
    "\n",
    "# Weight & bias (layer3 = 입력 20개 출력 10개) #바이어스는 출력 수를 따름\n",
    "W3=tf.Variable(tf.random_normal([20,10]),name=\"weight3\")\n",
    "b3=tf.Variable(tf.random_normal([10]),name='bias4') \n",
    "layer3=tf.nn.relu(tf.matmul(layer2,W3)+b3)\n",
    "\n",
    "# Weight & bias (layer4 (아웃풋 레이어)= 입력 10개 출력 1개) #바이어스는 출력 수를 따름\n",
    "W4=tf.Variable(tf.random_normal([10,1]),name=\"weight2\")\n",
    "b4=tf.Variable(tf.random_normal([1]),name='bias2') \n",
    "\n",
    "#은닉층은 relu 넣는것이 일반적\n",
    "\n",
    "\n",
    "# hypothesis\n",
    "# Logits=X@W+b \n",
    "logits=tf.matmul(layer3,W4)+b4\n",
    "#다중분류아니고 이중분류이므로 sigmoid\n",
    "H=tf.sigmoid(logits) \n",
    "\n",
    "# cast function\n",
    "cost=tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,labels=Y))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# session & 초기화\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(1,3001):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict={X:x_data, Y:y_data})\n",
    "    if step%300==0:\n",
    "        print(\"몇회째: {}, 코스트:{}\".format(step,cost_val))\n",
    "\n",
    "# predict\n",
    "predict = tf.cast(H>0.5,dtype=tf.float32)\n",
    "correct=tf.equal(predict,Y) #F,T,F,T\n",
    "accuracy = tf.reduce_mean(tf.cast(correct,dtype=tf.float32))\n",
    "print('정확도:',sess.run(accuracy, feed_dict={X:x_data,Y:y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ",  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
